{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import dlib\n",
    "#import face_recognition \n",
    "try:\n",
    "    import face_recognition_models\n",
    "except Exception:\n",
    "    print(\"Please install `face_recognition_models` with this command before using `face_recognition`:\\n\")\n",
    "    print(\"pip install git+https://github.com/ageitgey/face_recognition_models\")\n",
    "    quit()\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "predictor_68_point_model = face_recognition_models.pose_predictor_model_location()\n",
    "pose_predictor_68_point = dlib.shape_predictor(predictor_68_point_model)\n",
    "\n",
    "predictor_5_point_model = face_recognition_models.pose_predictor_five_point_model_location()\n",
    "pose_predictor_5_point = dlib.shape_predictor(predictor_5_point_model)\n",
    "\n",
    "cnn_face_detection_model = face_recognition_models.cnn_face_detector_model_location()\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(cnn_face_detection_model)\n",
    "\n",
    "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
    "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)\n",
    "\n",
    "\n",
    "def _rect_to_css(rect):\n",
    "    \"\"\"\n",
    "    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\n",
    "\n",
    "    :param rect: a dlib 'rect' object\n",
    "    :return: a plain tuple representation of the rect in (top, right, bottom, left) order\n",
    "    \"\"\"\n",
    "    return rect.top(), rect.right(), rect.bottom(), rect.left()\n",
    "\n",
    "\n",
    "def _css_to_rect(css):\n",
    "    \"\"\"\n",
    "    Convert a tuple in (top, right, bottom, left) order to a dlib `rect` object\n",
    "\n",
    "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
    "    :return: a dlib `rect` object\n",
    "    \"\"\"\n",
    "    return dlib.rectangle(css[3], css[0], css[1], css[2])\n",
    "\n",
    "\n",
    "def _trim_css_to_bounds(css, image_shape):\n",
    "    \"\"\"\n",
    "    Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\n",
    "\n",
    "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
    "    :param image_shape: numpy shape of the image array\n",
    "    :return: a trimmed plain tuple representation of the rect in (top, right, bottom, left) order\n",
    "    \"\"\"\n",
    "    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)\n",
    "\n",
    "\n",
    "def face_distance(face_encodings, face_to_compare):\n",
    "    \"\"\"\n",
    "    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n",
    "    for each comparison face. The distance tells you how similar the faces are.\n",
    "\n",
    "    :param faces: List of face encodings to compare\n",
    "    :param face_to_compare: A face encoding to compare against\n",
    "    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n",
    "    \"\"\"\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "\n",
    "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def load_image_file(file, mode='RGB'):\n",
    "    \"\"\"\n",
    "    Loads an image file (.jpg, .png, etc) into a numpy array\n",
    "\n",
    "    :param file: image file name or file object to load\n",
    "    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n",
    "    :return: image contents as numpy array\n",
    "    \"\"\"\n",
    "    im = PIL.Image.open(file)\n",
    "    if mode:\n",
    "        im = im.convert(mode)\n",
    "    return np.array(im)\n",
    "\n",
    "\n",
    "\n",
    "def _raw_face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
    "    \"\"\"\n",
    "    Returns an array of bounding boxes of human faces in a image\n",
    "\n",
    "    :param img: An image (as a numpy array)\n",
    "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
    "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
    "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
    "    :return: A list of dlib 'rect' objects of found face locations\n",
    "    \"\"\"\n",
    "    if model == \"cnn\":\n",
    "        return cnn_face_detector(img, number_of_times_to_upsample)\n",
    "    else:\n",
    "        return face_detector(img, number_of_times_to_upsample)\n",
    "\n",
    "\n",
    "def face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
    "    \"\"\"\n",
    "    Returns an array of bounding boxes of human faces in a image\n",
    "\n",
    "    :param img: An image (as a numpy array)\n",
    "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
    "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
    "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
    "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
    "    \"\"\"\n",
    "    if model == \"cnn\":\n",
    "        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, \"cnn\")]\n",
    "    else:\n",
    "        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n",
    "\n",
    "\n",
    "\n",
    "def _raw_face_locations_batched(images, number_of_times_to_upsample=1, batch_size=128):\n",
    "    \"\"\"\n",
    "    Returns an 2d array of dlib rects of human faces in a image using the cnn face detector\n",
    "\n",
    "    :param img: A list of images (each as a numpy array)\n",
    "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
    "    :return: A list of dlib 'rect' objects of found face locations\n",
    "    \"\"\"\n",
    "    return cnn_face_detector(images, number_of_times_to_upsample, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def batch_face_locations(images, number_of_times_to_upsample=1, batch_size=128):\n",
    "    \"\"\"\n",
    "    Returns an 2d array of bounding boxes of human faces in a image using the cnn face detector\n",
    "    If you are using a GPU, this can give you much faster results since the GPU\n",
    "    can process batches of images at once. If you aren't using a GPU, you don't need this function.\n",
    "\n",
    "    :param img: A list of images (each as a numpy array)\n",
    "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
    "    :param batch_size: How many images to include in each GPU processing batch.\n",
    "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
    "    \"\"\"\n",
    "    def convert_cnn_detections_to_css(detections):\n",
    "        return [_trim_css_to_bounds(_rect_to_css(face.rect), images[0].shape) for face in detections]\n",
    "\n",
    "    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)\n",
    "\n",
    "    return list(map(convert_cnn_detections_to_css, raw_detections_batched))\n",
    "\n",
    "\n",
    "\n",
    "def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
    "    if face_locations is None:\n",
    "        face_locations = _raw_face_locations(face_image)\n",
    "    else:\n",
    "        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\n",
    "\n",
    "    pose_predictor = pose_predictor_68_point\n",
    "\n",
    "    if model == \"small\":\n",
    "        pose_predictor = pose_predictor_5_point\n",
    "\n",
    "    return [pose_predictor(face_image, face_location) for face_location in face_locations]\n",
    "\n",
    "\n",
    "def face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
    "    \"\"\"\n",
    "    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\n",
    "\n",
    "    :param face_image: image to search\n",
    "    :param face_locations: Optionally provide a list of face locations to check.\n",
    "    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\n",
    "    :return: A list of dicts of face feature locations (eyes, nose, etc)\n",
    "    \"\"\"\n",
    "    landmarks = _raw_face_landmarks(face_image, face_locations, model)\n",
    "    landmarks_as_tuples = [[(p.x, p.y) for p in landmark.parts()] for landmark in landmarks]\n",
    "\n",
    "    # For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\n",
    "    if model == 'large':\n",
    "        return [{\n",
    "            \"chin\": points[0:17],\n",
    "            \"left_eyebrow\": points[17:22],\n",
    "            \"right_eyebrow\": points[22:27],\n",
    "            \"nose_bridge\": points[27:31],\n",
    "            \"nose_tip\": points[31:36],\n",
    "            \"left_eye\": points[36:42],\n",
    "            \"right_eye\": points[42:48],\n",
    "            \"top_lip\": points[48:55] + [points[64]] + [points[63]] + [points[62]] + [points[61]] + [points[60]],\n",
    "            \"bottom_lip\": points[54:60] + [points[48]] + [points[60]] + [points[67]] + [points[66]] + [points[65]] + [points[64]]\n",
    "        } for points in landmarks_as_tuples]\n",
    "    elif model == 'small':\n",
    "        return [{\n",
    "            \"nose_tip\": [points[4]],\n",
    "            \"left_eye\": points[2:4],\n",
    "            \"right_eye\": points[0:2],\n",
    "        } for points in landmarks_as_tuples]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid landmarks model type. Supported models are ['small', 'large'].\")\n",
    "\n",
    "\n",
    "\n",
    "def face_encodings(face_image, known_face_locations=None, num_jitters=1):\n",
    "    \"\"\"\n",
    "    Given an image, return the 128-dimension face encoding for each face in the image.\n",
    "\n",
    "    :param face_image: The image that contains one or more faces\n",
    "    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n",
    "    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n",
    "    :return: A list of 128-dimensional face encodings (one for each face in the image)\n",
    "    \"\"\"\n",
    "    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model=\"small\")\n",
    "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
    "\n",
    "\n",
    "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n",
    "    \"\"\"\n",
    "    Compare a list of face encodings against a candidate encoding to see if they match.\n",
    "\n",
    "    :param known_face_encodings: A list of known face encodings\n",
    "    :param face_encoding_to_check: A single face encoding to compare against the list\n",
    "    :param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n",
    "    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\n",
    "    \"\"\"\n",
    "    return list(face_distance(known_face_encodings, face_encoding_to_check) <= tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
